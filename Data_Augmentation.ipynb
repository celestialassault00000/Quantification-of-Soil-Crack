{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoKOALIZSZjw",
        "outputId": "deabd52f-81af-403b-9059-fa8cc0d8662a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWzWTSDi7IxQ"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(rotation_range =10,\n",
        "                         width_shift_range = 0.2,\n",
        "                         height_shift_range = 0.2,\n",
        "                         rescale=1./255,\n",
        "                         shear_range=0.2,\n",
        "                         zoom_range=0.2,\n",
        "                         horizontal_flip = True,\n",
        "                         fill_mode = 'nearest',\n",
        "                         data_format='channels_last',\n",
        "                         brightness_range=[0.1, 2])\n",
        "\n",
        "\n",
        "# img_dir = \"/content/gdrive/MyDrive/main/Not Cracked\" # Enter Directory of all images\n",
        "# data_path = os.path.join(img_dir,'*g')\n",
        "# files = glob.glob(data_path)\n",
        "# data = []\n",
        "# for f1 in files:\n",
        "#     img = cv2.imread(f1)\n",
        "#     data.append(img)\n",
        "#     x = img_to_array(img)\n",
        "#     x = x.reshape((1,) + x.shape)\n",
        "#     i = 0\n",
        "#     for batch in datagen.flow (x, batch_size=1, save_to_dir =r'/content/gdrive/MyDrive/main/Not Cracked',save_format='jpg'):\n",
        "#       i+=1\n",
        "#       if i==120:\n",
        "#         break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_dir = \"/content/gdrive/MyDrive/main/Cracked\" # Enter Directory of all images\n",
        "data_path = os.path.join(img_dir,'*g')\n",
        "files1 = glob.glob(data_path)\n",
        "print(len(files1))\n",
        "\n",
        "img_dir = \"/content/gdrive/MyDrive/main/Not Cracked\" # Enter Directory of all images\n",
        "data_path = os.path.join(img_dir,'*g')\n",
        "files2 = glob.glob(data_path)\n",
        "print(len(files2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Cf8xQ2iJ82d",
        "outputId": "2333e697-76c8-49cf-9cb8-81e1dc22814f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8824\n",
            "9179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4kLyhM-G7im"
      },
      "outputs": [],
      "source": [
        "img_dir = \"/content/gdrive/MyDrive/main/Cracked\" # Enter Directory of all images\n",
        "data_path = os.path.join(img_dir,'*g')\n",
        "files = glob.glob(data_path)\n",
        "data = []\n",
        "for f1 in files:\n",
        "    img = cv2.imread(f1)\n",
        "    data.append(img)\n",
        "    x = img_to_array(img)\n",
        "    x = x.reshape((1,) + x.shape)\n",
        "    i = 0\n",
        "    for batch in datagen.flow (x, batch_size=1, save_to_dir =r'/content/gdrive/MyDrive/main/Cracked',save_format='jpg'):\n",
        "      i+=1\n",
        "      if i==120:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmuogvKO8HYP",
        "outputId": "161d7c5e-3343-41d5-cdbb-26f7554cca52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8210 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.preprocessing.image.DirectoryIterator at 0x7f54f746d9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "datagen.flow_from_directory(\"/content/gdrive/MyDrive/Train\",batch_size=1,class_mode=\"categorical\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN7DWLOoHJ9_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n",
        "    # The first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fifth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a dense layer\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 128 neuron in the fully-connected layer\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    # 5 output neurons for 5 classes with the softmax activation\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-cmG6ORHRpP",
        "outputId": "d039a54c-a746-4348-d83c-a5f87467c172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 198, 198, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 99, 99, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 97, 97, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 48, 48, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 46, 46, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 23, 23, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 21, 21, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 10, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               131200    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 229,285\n",
            "Trainable params: 229,285\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NziGEh9oHX06",
        "outputId": "b8b601ca-6ed1-4d04-998c-0e34344b97ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXfeHjK4H4Dl",
        "outputId": "ab1f1e42-49e1-45ee-a864-449a2ecd67ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8210 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "        \"/content/gdrive/MyDrive/Train\",  # This is the source directory for training images\n",
        "        target_size=(200, 200),  # All images will be resized to 200 x 200\n",
        "        batch_size=1,\n",
        "        # Specify the classes explicitly\n",
        "        classes = [\"positive\",\"Negative\"],\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQrW77EiLRUB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMOlXtlyme1l",
        "outputId": "bc97e40b-7d1b-4522-95f7-39818a3a0d49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28210 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = datagen.flow_from_directory(\"/content/gdrive/MyDrive/Train\", batch_size = 2, class_mode = 'binary', target_size = (224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-qDoCc2Kx3H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0BELbQPpiWi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from pathlib import Path\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Vot48reAddO",
        "outputId": "9f7b9442-6858-4637-f511-b039fcdc8060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22568 images belonging to 2 classes.\n",
            "Found 72 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2) # set validation split\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\"/content/gdrive/MyDrive/Train\"\n",
        "    ,\n",
        "    batch_size=1,\n",
        "    class_mode='binary',target_size=(32,32),\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/data\", # same directory as training data\n",
        "    batch_size=1,target_size=(32,32),\n",
        "    class_mode='binary') # set as validation data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGN3tq5ZBjOB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEPe5e1yBmES"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape = (200,200,3)),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_Dz3LYABpLz",
        "outputId": "7f1c7393-38f3-4099-a108-df9315cff8d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 120000)            0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               15360128  \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,360,257\n",
            "Trainable params: 15,360,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvCVCS3mBsR7"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGMr_w3WBv4H",
        "outputId": "e73052c1-a694-4785-d049-0d96aae90d82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 6s 268ms/step - loss: 61.2869 - accuracy: 0.4000 - val_loss: 21.0871 - val_accuracy: 0.3750\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 7s 324ms/step - loss: 7.8199 - accuracy: 0.8500 - val_loss: 16.4758 - val_accuracy: 0.3750\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 7s 371ms/step - loss: 6.9320 - accuracy: 0.6000 - val_loss: 7.9078 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 11.1541 - accuracy: 0.4500 - val_loss: 10.4355 - val_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 6s 299ms/step - loss: 5.1393 - accuracy: 0.9500 - val_loss: 20.3877 - val_accuracy: 0.2500\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 7s 333ms/step - loss: 13.2831 - accuracy: 0.5000 - val_loss: 15.5408 - val_accuracy: 0.3750\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 6s 277ms/step - loss: 3.8560 - accuracy: 0.8000 - val_loss: 6.6544 - val_accuracy: 0.2500\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 6s 284ms/step - loss: 4.2422 - accuracy: 0.6000 - val_loss: 4.8421 - val_accuracy: 0.3750\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 4s 215ms/step - loss: 3.9403 - accuracy: 0.4500 - val_loss: 3.2364 - val_accuracy: 0.6250\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 7s 369ms/step - loss: 13.6228 - accuracy: 0.3000 - val_loss: 8.0057 - val_accuracy: 0.1250\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 6s 289ms/step - loss: 10.3375 - accuracy: 0.6000 - val_loss: 27.0891 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 5s 243ms/step - loss: 4.5718 - accuracy: 0.9000 - val_loss: 50.4502 - val_accuracy: 0.2500\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 5s 261ms/step - loss: 22.3816 - accuracy: 0.6000 - val_loss: 57.2101 - val_accuracy: 0.1250\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 5s 252ms/step - loss: 22.4785 - accuracy: 0.7500 - val_loss: 22.9727 - val_accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 5s 235ms/step - loss: 20.6427 - accuracy: 0.2000 - val_loss: 5.1455 - val_accuracy: 0.2500\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 4s 199ms/step - loss: 2.6133 - accuracy: 0.6500 - val_loss: 5.2004 - val_accuracy: 0.7500\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 5s 254ms/step - loss: 9.8155 - accuracy: 0.6500 - val_loss: 27.8705 - val_accuracy: 0.2500\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 5s 241ms/step - loss: 9.2867 - accuracy: 0.7500 - val_loss: 13.0717 - val_accuracy: 0.6250\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 6s 297ms/step - loss: 14.0424 - accuracy: 0.6500 - val_loss: 2.2005e-15 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 5s 243ms/step - loss: 9.0707 - accuracy: 0.7000 - val_loss: 1.0976 - val_accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator,\n",
        "      steps_per_epoch=20,\n",
        "      epochs=20,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6qAw-i7CdIA",
        "outputId": "84092e0c-8e3b-44c0-e30b-1ee6093657b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72/72 [==============================] - 3s 46ms/step - loss: 0.5782 - accuracy: 0.7778\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5781863331794739, 0.7777777910232544]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "model.evaluate(validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9J5ICc7C-WT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "model2 = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n",
        "    # The first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fifth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a dense layer\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 128 neuron in the fully-connected layer\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    # 5 output neurons for 1 classes with the softmax activation\n",
        "    tf.keras.layers.Dense(1, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Conv2D(8,(3,3),activation='relu', padding='same', input_shape=(200,200,3)))\n",
        "model.add(keras.layers.MaxPooling2D(3,3))\n",
        "model.add(keras.layers.Conv2D(16,(3,3),activation='relu', padding='same'))\n",
        "model.add(keras.layers.MaxPooling2D(3,3))\n",
        "model.add(keras.layers.Conv2D(32,(3,3),activation='relu', padding='same'))\n",
        "model.add(keras.layers.MaxPooling2D(3,3))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(2048,activation='relu'))\n",
        "model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history2 = model.fit(train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=15,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "KzMojLuMwOj3",
        "outputId": "691e4cb2-985e-4581-a456-7e7a8788e5ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.7922 - accuracy: 0.7000 - val_loss: 1.0603 - val_accuracy: 0.2500\n",
            "Epoch 2/15\n",
            " 95/100 [===========================>..] - ETA: 1s - loss: 0.4819 - accuracy: 0.8000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-f1fff463da6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       validation_steps=20)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hj72SZM8yBQ",
        "outputId": "457a5faa-d4fe-48c0-b420-942ce7a4dd4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72/72 [==============================] - 3s 35ms/step - loss: 22.8422 - accuracy: 0.1389\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[22.84222412109375, 0.1388888955116272]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPtWDZLDDI8t"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# model2.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=RMSprop(lr=0.001),\n",
        "#               metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFrmvEM6FHQK"
      },
      "outputs": [],
      "source": [
        "model2.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vQXWYIlDL2G",
        "outputId": "9b912948-3e48-4932-b669-e7644540d039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "100/100 [==============================] - 24s 236ms/step - loss: 1.2833 - accuracy: 0.6700 - val_loss: 0.7243 - val_accuracy: 0.1500\n",
            "Epoch 2/15\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.6676 - accuracy: 0.6000 - val_loss: 1.4546 - val_accuracy: 0.2000\n",
            "Epoch 3/15\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.4372 - accuracy: 0.7400 - val_loss: 21.2577 - val_accuracy: 0.3000\n",
            "Epoch 4/15\n",
            "100/100 [==============================] - 23s 232ms/step - loss: 0.5768 - accuracy: 0.7000 - val_loss: 0.6803 - val_accuracy: 0.3000\n",
            "Epoch 5/15\n",
            "100/100 [==============================] - 24s 241ms/step - loss: 0.7421 - accuracy: 0.7200 - val_loss: 0.8295 - val_accuracy: 0.3500\n",
            "Epoch 6/15\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.6025 - accuracy: 0.7500 - val_loss: 1.3955 - val_accuracy: 0.2000\n",
            "Epoch 7/15\n",
            "100/100 [==============================] - 23s 232ms/step - loss: 0.7008 - accuracy: 0.6000 - val_loss: 0.7398 - val_accuracy: 0.2500\n",
            "Epoch 8/15\n",
            "100/100 [==============================] - 23s 231ms/step - loss: 0.6597 - accuracy: 0.6700 - val_loss: 0.7776 - val_accuracy: 0.3500\n",
            "Epoch 9/15\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.6104 - accuracy: 0.7300 - val_loss: 0.8959 - val_accuracy: 0.2500\n",
            "Epoch 10/15\n",
            "100/100 [==============================] - 26s 259ms/step - loss: 0.6176 - accuracy: 0.7100 - val_loss: 0.8921 - val_accuracy: 0.2000\n",
            "Epoch 11/15\n",
            "100/100 [==============================] - 24s 236ms/step - loss: 0.5877 - accuracy: 0.7400 - val_loss: 0.8972 - val_accuracy: 0.2000\n",
            "Epoch 12/15\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.6470 - accuracy: 0.6700 - val_loss: 0.9524 - val_accuracy: 0.1500\n",
            "Epoch 13/15\n",
            "100/100 [==============================] - 24s 236ms/step - loss: 0.6357 - accuracy: 0.6900 - val_loss: 0.8631 - val_accuracy: 0.3500\n",
            "Epoch 14/15\n",
            "100/100 [==============================] - 25s 252ms/step - loss: 0.5467 - accuracy: 0.7800 - val_loss: 1.2244 - val_accuracy: 0.2000\n",
            "Epoch 15/15\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 1.0197 - accuracy: 0.7500 - val_loss: 0.7346 - val_accuracy: 0.3000\n"
          ]
        }
      ],
      "source": [
        "history2 = model2.fit(train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=15,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuaDJHzlEbab",
        "outputId": "be2a8167-33f2-48dd-e13a-d9d5db7e2ddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72/72 [==============================] - 3s 37ms/step - loss: 0.7442 - accuracy: 0.2500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7441622614860535, 0.25]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "model2.evaluate(validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_dir = \"/content/gdrive/MyDrive/data/Positive\" # Enter Directory of all images\n",
        "data_path = os.path.join(img_dir,'*g')\n",
        "files = glob.glob(data_path)\n",
        "data = []\n",
        "for f1 in files:\n",
        "    img = cv2.imread(f1)\n",
        "    data.append(img)\n",
        "    x = img_to_array(img)\n",
        "    x = x.reshape((1,) + x.shape)\n",
        "    i = 0\n",
        "    for batch in datagen.flow (x, batch_size=1, save_to_dir =r'/content/gdrive/MyDrive/data/Positive',save_format='jpg'):\n",
        "      i+=1\n",
        "      if i==10:\n",
        "        break\n",
        "img_dir = \"/content/gdrive/MyDrive/data/negative\" # Enter Directory of all images\n",
        "data_path = os.path.join(img_dir,'*g')\n",
        "files = glob.glob(data_path)\n",
        "data = []\n",
        "for f1 in files:\n",
        "    img = cv2.imread(f1)\n",
        "    data.append(img)\n",
        "    x = img_to_array(img)\n",
        "    x = x.reshape((1,) + x.shape)\n",
        "    i = 0\n",
        "    for batch in datagen.flow (x, batch_size=1, save_to_dir =r'/content/gdrive/MyDrive/data/Negative',save_format='jpg'):\n",
        "      i+=1\n",
        "      if i==10:\n",
        "        break"
      ],
      "metadata": {
        "id": "eSdI2BlwFzNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2) # set validation split\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\"/content/gdrive/MyDrive/Train\"\n",
        "    ,\n",
        "    batch_size=1,\n",
        "    class_mode='binary',target_size=(32,32),\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/data\", # same directory as training data\n",
        "    batch_size=1,target_size=(32,32),\n",
        "    class_mode='binary') # set as validation data\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdyqCDl7Bri0",
        "outputId": "0e4448fe-9706-4061-c207-04db2a213d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22568 images belonging to 2 classes.\n",
            "Found 596 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGCbrSjCEaS_",
        "outputId": "fdaf90ad-1383-4fa8-bf44-e2010c35833e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(32, (2, 2), input_shape=(32,32,3)))\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(keras.layers.Conv2D(32, (2, 2)))\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(keras.layers.Conv2D(64, (2, 2)))\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(64))\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "#model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(1))\n",
        "model.add(keras.layers.Activation('sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "\t\t\toptimizer=optimizer,\n",
        "\t\t\tmetrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "zf3V6lS6_xwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator,\n",
        "      steps_per_epoch=10,\n",
        "      epochs=15,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "vKFk7sojAYY1",
        "outputId": "f1dbe0d0-1412-4cc6-a6d9-24ffc6a59d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "10/10 [==============================] - 15s 2s/step - loss: 0.7571 - accuracy: 0.4000 - val_loss: 0.6380 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3bf60ab29c56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       validation_steps=20)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1371\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxnMSQyeBiWR",
        "outputId": "ed48a10e-eec3-4aae-c3ed-7ae5f6add944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "596/596 [==============================] - 10s 16ms/step - loss: 0.4124 - accuracy: 0.9698\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.41241320967674255, 0.9697986841201782]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(train_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        },
        "id": "Feo2Pq6dVJEM",
        "outputId": "e47f3abf-1a50-4166-dc7a-66b537832d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15425/22568 [===================>..........] - ETA: 1:02:37 - loss: 0.6767 - accuracy: 0.7100"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7e0d9e4b9c23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nOSError: [Errno 5] Input/output error\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 114, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\nOSError: [Errno 5] Input/output error\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_test_function_1582]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(validation_generator)"
      ],
      "metadata": {
        "id": "2ftSx0AaXmI2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}